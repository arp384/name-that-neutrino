{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do_processing.ipynb\n",
    "## Author: Andrew Phillips\n",
    "## Purpose: Selects NTN phase 1 dataset from raw i3 sim files, applies custom modules, and saves to csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os, fnmatch\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "from icecube import dataio, dataclasses, icetray, MuonGun\n",
    "from I3Tray import *\n",
    "from icecube.hdfwriter import I3HDFWriter\n",
    "import h5py\n",
    "from i3_tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in file paths, and corresponding subject set ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_info = pd.read_csv(os.path.join(os.getcwd(), 'phase1_files.csv'))\n",
    "i3_files = list(file_info['filepath'])\n",
    "subj_set_ids = list(file_info['subject_set_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select only desired events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dict of subj_set_ids, where data is list of all (event_id, subject_id) pairs in that subject set\n",
    "ntn_subjects = pd.read_csv('/home/aphillips/data/data_exports_3-30/name-that-neutrino-subjects.csv')\n",
    "ntn_subjects = ntn_subjects[ntn_subjects['workflow_id']==23715]\n",
    "ssid_dict = dict.fromkeys(subj_set_ids)\n",
    "for subj_set_id in subj_set_ids:\n",
    "    subj_set = ntn_subjects[ntn_subjects['subject_set_id'] == subj_set_id]\n",
    "    metadata = subj_set['metadata']\n",
    "    subject_ids = list(subj_set['subject_id'])\n",
    "    evt_ids = [json.loads(md)['event'] for md in metadata]\n",
    "    val = zip(subject_ids, evt_ids)\n",
    "    ssid_dict[subj_set_id] = [tup for tup in zip(subject_ids, evt_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 17 of 19\n",
      "112119\n",
      "classifier_rehyd_DST_IC86.2020_NuE.022067.001999.i3.zst\n",
      "Processing file 18 of 19\n",
      "112118\n",
      "classifier_rehyd_DST_IC86.2020_NuE.022067.000999.i3.zst\n",
      "Processing file 19 of 19\n",
      "112120\n",
      "classifier_rehyd_DST_IC86.2020_NuE.022067.009999.i3.zst\n"
     ]
    }
   ],
   "source": [
    "for idx in range(0, len(subj_set_ids)): #loop over all the ssids\n",
    "    \n",
    "    print(f'Processing file {idx+1} of {len(subj_set_ids)}')\n",
    "    ssid = subj_set_ids[idx]\n",
    "    event_ids = [tup[1] for tup in ssid_dict[ssid]]\n",
    "    event_ids = list(set(event_ids))\n",
    "    subject_ids = [tup[0] for tup in ssid_dict[ssid]]\n",
    "    event_ids.sort() #sort the event_ids. this should speed things up since the \n",
    "    outfile = dataio.I3File(os.path.join('/home/aphillips/data/output', f'ntn_events_{ssid}.i3'), 'w') #open empty i3 for output\n",
    "    infile = dataio.I3File(i3_files[idx]) #open target i3\n",
    "\n",
    "    while(infile.more()):\n",
    "        frame = infile.pop_daq() #pop frame\n",
    "        evt_head = frame[\"I3EventHeader\"] #get event header\n",
    "        evt_id = evt_head.event_id #get event id\n",
    "        if(evt_id == event_ids[0]): #check if event id is in our list\n",
    "            frame['subject_id'] = icetray.I3Int(subject_ids.pop(0))\n",
    "            outfile.push(frame) #if so, push the frame to our output file\n",
    "            event_ids.pop(0) #remove that value from the list of event ids\n",
    "        if event_ids == []: #stop when we've grabbed all of our event ids\n",
    "            break   \n",
    "                            \n",
    "    outfile.close() #close the files\n",
    "    infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply custom modules, save to csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "for f in [fname for fname in os.listdir('/home/aphillips/data/output/') if fname != 'output']:\n",
    "    #print(f)\n",
    "    (outfile, hd5_name) = apply_modules(os.path.join('/home/aphillips/data/output/',f), '/home/aphillips/data/output/')\n",
    "    dataframes.append(process_data(os.path.join(os.getcwd(), 'output', hd5_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate all the csvs into a master df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.concat(dataframes) #create a master dataframe\n",
    "DF.to_csv('/home/aphillips/data/output/all_ntn_events_4-24-24.csv', index=False) #save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
